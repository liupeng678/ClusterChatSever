

# ClusterChatSever



# How to use it ? 
1. 安装mysql， 更改root密码为root, 设置监听地址为所有，而不是本地， 并且mysql -u root  -p 的命令前面不要加sudo就能进去。 不然代码接口访问不了mysql。 此外还要安装 sudo apt-get install libmysqlclient-dev ， 这是开发的依赖库。 
2. git clone 代码， 将代码拷贝到本地。 
3. 安装配置nignx
- + ./configure --with-stream ， 缺什么安装什么 sudo apt-get install libpcre3 libpcre3-dev   sudo apt-get install openssl libssl-dev

- +  make && make install   编译完成后，默认安装在了/usr/local/nginx目录。
- +  修改nginx配置文件内容为ClusterChatSever/test/conf/nginx.conf中的内容。 
- + 这里除了自己把字母拼错， 出现了两个问题，一个是没有shared 库， 这里面我就参照【3】做了，然后又出现了 [error] open() "/usr/local/nginx/logs/nginx.pid" failed (2: No such file or directory)问题， 参照【4】解决。最后进入安装的nginx/bin 中 nginx -s reload成功。 
4.  配置redis  这里就不介绍了， 和nginx差不多， 记得在cmake中添加依赖库。 
5. 运行调试， 发现之前ginx设置的断开链接事件太短了。 需要注意一下，而且监听的端口要设置成路由器分配给网卡的路由。
6. 运行的效果正常。





## 1 背景
 秋招在急，简历中没有一个合适的项目供面试官去展开提问和自己去练习。  而且在学习c++的过程中最大的问题就是没有合适的项目去融汇贯通， 不知道做什么才好，像java可以做很多有意思的后台项目， 但是c++貌似如果只是懂语法去做这些后台项目很难， 不知道从什么点出发去做。我想通过这个项目去掌握C++如何开发后台项目。  通过这个项目明白后台的开发流程， 让自己的c++能够做到实际开发的水平， 敢写c++。
 
 ## 2 任务
实现一个集群聊天服务器， 能够高并发的接收客服端的请求。 通过这个项目掌握
1. 掌握服务器的网络I/O模块，业务模块，数据模块分层的设计思想， ORM
2. 掌握C++ muduo网络库的编程以及实现原理
3. 掌握Json的编程应用
4. 掌握nginx配置部署tcp负载均衡器的应用以及原理
5. 掌握服务器中间件的应用场景和基于发布-订阅的redis编程实践以及应用原理
6. 掌握CMake构建自动化编译环境
7. 掌握Github管理项目
8. 熟悉现代c++， 尤其是绑定器和function等使用， 掌握面向对象设计的思想。 


 ## 3 行动

 ### 1. 环境配置
 1. vscode + 远程linux

 ### 2.  整体实现思路
客户端：
用户过来进入登录或者注册页面。 如果选择登录的话， 我们发送一个json给服务器， 服务器返回该用户的信息， 例如好友列表， 群组， 离线消息。 登录成功之后，  我们将个人信息展示出来， 离线的群组消息和个人消息展示出来。 然后开启一个线程阻塞等待接受到的消息。之后主线程进入到聊天页表内。 另外一个主线程的业务是注册， 这个就不说了，很简单的一个。 我们继续说一下聊天业务中， 子线程阻塞去接受网卡的数据，这是因为别人发送消息自己要去接收，有消息就展示出来。 
- + 聊天业务有很多，我们通过一个<string ,function> 的map表存储回调函数对象。 string存函数的stringname , function里面传入函数名作为绑定。 这个函数名对应的函数要符合function定义的接受函数的类型。 这样的话娿我们就做到了解耦。 这样我们在聊天业务中去循环接受参数， 如果参数的函数名在回调函数的map表中找到的话， 我们就将fd 和字符串内容传递进去。 下面我们分析一下各个任务
  （1） 添加好友任务就string的数据转换后才能json，并配置对应的信息标识后发送给服务器。 如果添加失败的话，服务器会返回错误代码的。 
  （2） 聊天任务是将当前用户信息和消息以及发送的内容给服务器， 设置好对应的消息标识。
  （3） 创建群组的业务也是一样，需要发送自己的id和群名字和信息等。
  （4） 添加群组的任务发送自己的信息和想添加的群组id给服务器。
  （5） 群组聊天的话发送自己的信息和内容给群组id . 

服务器 ：

1. ChatServer这个类封装网络层， 这个层的绑定自身类中的两个函数作为链接回调和接收回调。连接回调就不说了，直接拿到回调的fd进行关闭操作。 一般正常链接的话muduo自动放入epoll之后再触发这个事件。  数据接收回调的话 首先解析字符串成json， 之后会调用ChatService这个单例类的处理方法的函数，传入的就是这个json的消息id, 这个任务处理函数返回的是函数对象， 我们接收到函数对象之后传入fd， json数据和超时时间。 
2. ChatService 这个是业务类， 业务类的话只用一个单例就可以， 创建多个并没有意义，而且在多线程状态下，如果创建多个业务类的话， 一个请求来一个业务类，一个业务类被频繁的创建和销毁， 很浪费资源，而且避免了我们将一个统计变量弄成全局变量去统计， 全部在自己这个变量中去操作 。这个类绑定了很多自己的成员函数， 这些成员函数大部分的接受字符是fd + ** , 这些参数不一致情况的通过bind去填补。这个类有一些很重要的成员变量，四张表的对象类， redis的操作类， 互斥锁， 还有一个函数对象的hash_map表。  这个业务中会经常调用这些数据类。 





###  3 框架
  整体的框架如下， 多个服务器通过redis构建互通信息， 然后将多个服务器绑定到niginx上，与客户端交互。 服务器采用muduo库作为网络库底层， 以muduo库提供的回调作为业务层， 以自己封装的数据库类作为数据层的MVC结构进行开发。最终实现了一个高并发的集群服务器。 
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210522133518257.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdXBlbmcxOTk3MDExOQ==,size_16,color_FFFFFF,t_70)


 ### 4. 技术栈
 C++, linux , cmake , mysql , redis , nginx , muduo , gdb , git, json



 ### 5. 具体步骤

 1. 学习json和json开源库
 - +   数据交换语言是独立于编程语言的， 不同编程语言通信时通过json等交换语言进行。 json是一个比较简单的字节流交换语言。 通过key-value存储数据。 我们使用一个开源库 ， 他可以支持很多语言的json序列化和反序列化（也就是转换成数据类型或数据类型变成json）。用的时候也比较方便， 直接倒入一个头文件就行， 具体序列化实现都在这个文件文件中做了。 


2. muduo 网络库使用和学习
-  + 编译安装参照【1】， 这里面我已经装好了。 
-  +  muduo和众多网络库都是epoll+ 线程池的高性能服务器设计。 可以让我们直接关注到连接断开读写这几个事件的callback业务层， 请求来了底层自动调用callback。 
-  + 学会使用muduo开发一个基本的高并发服务器。 

3. cmake的使用与学习
- + 在vscode上配置cmake 辅助工具(界面操作+代码提示与检查)， 便于操作linux系统中的cmake. 
- + 基本的编译程序所做的命令例如：g++ -o server -g muduo_server.cpp xx.cpp -l/usr/include -L/usr/ib -Imuduo_net -lmuduo_base -lpthread  都可以在cmake中找到对应的配置选项， 去自动生成makefile。 
- +  cmakelists.txt 真的很强， 通过add_subdirectory(src) 去找子cmakelists.txt去编译。 


4. mysql 学习
- + mysql 安装与账号、权限配置
- + 创建业务需要用到的数据库和表。
```sql
CREATE TABLE IF NOT EXISTS user (id INT  AUTO_INCREMENT PRIMARY KEY  , name VARCHAR(50) NOT NULL UNIQUE ,  password VARCHAR(50) NOT NULL  , state   ENUM('online', 'offline')  DEFAULT 'offline'   )ENGINE=InnoDB DEFAULT CHARSET=utf8;


CREATE TABLE IF NOT EXISTS friend (userid INT NOT NULL , friendid  INT NOT NULL  ,PRIMARY KEY (userid,friendid) )ENGINE=InnoDB DEFAULT CHARSET=utf8;


CREATE TABLE IF NOT EXISTS allgroup (id INT  AUTO_INCREMENT PRIMARY KEY  , groupname VARCHAR(50) NOT NULL UNIQUE ,  groupdesc VARCHAR(200) DEFAULT ''  )ENGINE=InnoDB DEFAULT CHARSET=utf8;

CREATE TABLE IF NOT EXISTS groupuser (groupid INT  NOT NULL , userid int  NOT NULL , grouprole   ENUM('creator', 'normal')  DEFAULT 'normal'  ,PRIMARY KEY (groupid,userid) )ENGINE=InnoDB DEFAULT CHARSET=utf8;


CREATE TABLE IF NOT EXISTS offlinemessage (userid INT NOT NULL , message  VARCHAR(500) NOT NULL  )ENGINE=InnoDB DEFAULT CHARSET=utf8;
```


4. 创建源代码目录
整个项目在src，include中分为后台和客户端。 各种目录的编译通过各级的cmakelist.txt去控制。 

5.  开发网络模块，搭建业务模块, 定义消息类型
- + 我们使用muduo库开发网络层，在网络层的回调中， 设置了单例的业务类， 根据自身消息的id在业务类的map回调函数表中找对应的处理函数， 至此网络模块不再变动添加，完全解耦。 
- + 消息类型如下： {"msgid" : 4 , "name" : "zhang san", "password" : "123456"}
- + 

6. 封装mysql数据库类
- +  像orm框架一样， 用类封装数据库操作， 这样当数据库的代码有所变动，例如表的变动， 不会变动业务代码。
- + 使用时候我们先将一个表定义成一个表类， 定义一个数据库连接类， 定义一个数据库封装类， 这个类包传入表类和包含数据库连接类， 在封装类中将表类中数据传递到数据库连接类（数据库连接类依赖mysql的客户端包）。
- + 简单的传入一两个数据的话，不用再添加一个数据类。 直接定义一个数据库操作类。
- + 说一下各个数据表的作用：
- + redis类封装了redis接口类， 当订阅的id传入给redis服务器之后，初始化业务类的成员函数为一个函数对象。 并给一个子线程接口， 这个子线程一直while， 当有订阅内容过来的时候， 将内容传给这个函数对象， 也就是业务类成员函数。 （这个子线程好像是在connect里面弄得， 但是sub时候把上下文添加进去）。
- + mysql底层的驱动库， 这里面封装了查询语句， 给个类。
- + friend 数据类： 添加好友关系到表， 查询用户的好友表（）

7. 编写业务模块类
- + 编写了数据库类之后，我们开始关注业务层。 注意数据库层一般是辅助业务层的， 所以不能在一开始就写完数据层，而是业务层缺什么补什么。 
- + 首先来看登录业务， 我们根据输入的信息 要去users数据操作类中设置一个函数查找对应id的数据，判断是否账号密码匹配。 当匹配的话进入业务逻辑： 判断如果没有登录过，也就是users数据库的内容为offine后， 我们使用lock_guard 这种对象绑定创建的锁，控制这个类的当前在线用户列表添加这个数据， 通过生命周期释放。还要向redis注册这个id， 并且将自身的成员函数绑定到redis的回调中，如果这个id有事件了， 会过来通知。 此外拿着这个表去好友表查， 群组表查，离线表查， 
- + 注册业务比较简单了， 将json数据放入user对象之后， 传入到数据库操作类定义的insert函数中对接数据库sql。不用加锁。
-  + 退出业务的话删除在线用户从在线map中。 redis取消这个id的订阅，user表设置该id状态为离线。 
- +  添加客户端异常退出， 这个不是回调业务， 而是当服务器退出时候需要处理业务类的数据，清空在线状态。此外当我们调试阶段会主动关闭服务器， 导致里面的业务数据来不及更新。 因此添加ctrl +c 接收函数， 处理退出时候的业务重置。这个放到main函数里面。 但是好像不怎么解耦， 不过业务重置所在的类实单例业务类， 也没事。
- +  点对点聊天业务： 定义好发送信息的json格式之后，一个用户往另外一个用户发送的数据服务器判断当前这个表是否存在这个用户id， 存在的话往在线的用户fd直接socket send 数据。 不存在的话如果检测在线， 就去redis里面去发送。 不在线的话就保存数据到离线数据库中。 
- + 离线业务比较简单，而且不是单独的业务，而是一个放在其他业务的子服务（例如当登录的时候先去调用这个数据库封装类看有无消息）。 而且其数据表比较简单， 所以我们不用设计数据对象， 直接封装数据库操作类， 传入的参数为整数和string即可。 
- + 加好友的业务 ： 当对应添加id的数据来的话， 对friend表进行insert， 此外还要将好友数据类的多表联合查询功能提供给登录业务， 一开始的时候就要显示当前登录账号的好友。 
- + 创建群的业务 ： group 是需要定义一个对象来存储数据的， group数据类内部封装了两个表， 有一个数据库对象负责创建群的和管理这个群用户之间的关系。 
- + 加入群业务： 将自己的信息和用户id加入到group这个表中， 成员为normal.
- + 群聊天业务： 创建一个锁之后， 对从group中查询的用户信息进行判断，如果在本机就直接发送， 在线但是不在本机使用redis push， 其他的离线存储


8. 编写客户端
- +  完成服务器之后，我们使用简单的多线程开发一个termail客户端。 客户端通过主线程管理聊天过程， 子线程阻塞接收服务器的发送信息。 此外通过functional 绑定自身的函数， 将switch选择调用函数的耦合度较低代码做成闭合的代码。
- +   一些交互的代码这里就不再补充了。 如果出错的话或者不出错但是逻辑输出不对，记得调试一下。 还是说一下吧， 

9. 加入nginx负载均衡器
- + 我们主要使用nginx的负载均衡器， 注意这里使用的是tcp负载均衡模块。 本来一台是1-2w并发， 但是nginx能够轻松5-6w， 因此多加几个应用服务器后可以达到5-6w， 此外还可以nginx可以集群， 在前面加硬件的LVS负载均衡。
- + 负载算法有轮询， 一致性哈希（在短链接中经常用，http服务器中经常问），负载权重等。 
- + 此外聊天服务是长连接服务， 服务器发送给客户端还需要进行负载均衡器。 也有直接发送client，不经过nginx的服务器。 
- + nginx还有心跳检测功能，保证服务器一直正常工作。 还有支持动态加载配置文件， 不用重启就可以更换添加应用服务器。 
- +  应用服务器启动后， nginx会自动管理他们。 我们访问nginx时候会转发给响应的服务器。 


10. redis 解决跨服务器之间的数据交互
- + 当client1和client2登录在不同的服务器上， client1的userconnmap里面找不到client2的信息， 因为虽然是在线的， 但是他登录在其他的服务器上。 这个问题怎么解决呢？ 我们先在userconnmap找， 如果找不到再去数据库找这个用户是不是online, online的话代表在其他服务器上， 那么这就还有一个问题， 如果把数据发过去呢？我虽然知道他在其他服务器上，但是不知道具体在哪个。那么得两两相互连接，每一台服务器要和其他服务器互相连接。 这会代码的耦合性非常高。因此我们使用服务器中间件中的消息队列中间件。 像比较出名的kafka（还支持分布式部署的）, rabbitmq都是， 但是我们这个项目比较简单，就只用个基于发布订阅的redis就行。（注意这里我们没有使用redis的key-value这些内容，而是用了redis的一个发布订阅的小功能。 ） 
- + 基于发布订阅的redis ： 每一个用户在chat服务器上登录时 ，都会去redis上订阅自己的id相关的消息,当别人发送消息时候，本地找不到，数据库显示在线状态， 就肯定在redis中， 就执行publish消息给redis。 redis将消息notify给订阅这个主题的人。 
- + redis首先是一个强大的缓存服务器，比memcache强大很多，不仅仅支持多种数据结构（不像memcache
只能存储字符串）如字符串、list列表、set集合、map映射表等结构，还可以支持数据的持久化存储
（memcache只支持内存存储），经常被应用到高并发的服务器环境设计之中。
- + 安装redis服务器，客户端登录后测试，并且安装客户端源码，里面包含了开发库和头文件。  
- +  如何将redis的代码加入到之前的项目中呢？ 在登录的时候连接redis，设置上报时候的回调函数（bind+fc） des订阅主题。 单点或者群聊天的时候如果online本地找不到的话记得加publish。 上报设置的回调是别人发送消息时候redis服务器notice过来时候会自动调用的。 回调里面是在这个服务器的con连接中找到对方要发的con， 进行推送。 
 


## 6 结果
完成服务器的搭建。 高并发高可用。 


## 7 问题记录

### 编程问题

1. define 内容别的地方引用时候要在头文件里面define才能用到。 
2. g++  muduo_server.cpp  -o server -lmuduo_net  -lmuduo_base -lpthread  这个连接库是有依赖关系的， 最基础的在最前面。 
3. hpp代表head file combine with cpp file
4. sudo  netstat  -tanp 查看端口对应的进程。 
5. 回调之前一直不理解， c++回调基本全部用bind+ functional 去代替了， 因为普通函数回调限制较多不能携带使用类变量。 回调贯穿了整个程序oop的解耦操作中， 当一个函数什么时候发生和发生时候怎么做不再一起，就要事先设置回调。 供其他程序调用发生时候启动。（其实可以写到其他程序那部分， 但是不能解耦。）这个项目中我们将业务封装到了业务类中， 当网络这块回调被epoller-wait启动后根据数据的id拿到业务类的对应方法进行调用(通过bind+ fc+ map)。 业务再怎么改， 这边代码都不动了。 真正解耦。 
6. 头文件负责定义类还有添加头文件（定义时候需要用到的） ， 注意只需要编译一次。 对应的.cpp 负责具体实现， 当我们将其编译成库的时候， 就只需要头文件了， 具体源码实现都在.so中， 不用库的话， 也会自动去找.cpp的实现。当然我们有时候不需要这个cpp文件，类直接在hpp里面定义并声明完成。  
7. 当形参变量和类成员变量的名字一样时候，一定要加this区分。 
8. 如何设计开源文件的目录， bin放可执行文件  ， lib是生成的库文件 ， include是头文件， src 是源码， build 项目编译时候产生的临时文件， test放的代码， cmakelist.txt 设计编译文件的规则,  autobuild.sh 自动编译， readme.md 。 
9. 公网链接的时候， 服务器绑定自己内网网卡的地址， 客户端访问服务器所连接的公网地址， 请求过来之后自然会通过路由找到内网所在的网卡。建立链接。 
10. 当程序从看的角度找不到问题， 就只能调试了， gdb打断点break到出问题的之前点， 然后run， next，排除问题。 而且很多知名的开源代码会经常使用基类指针的运行时多态， 如果不走运行调试分析， 很难理清整体的框架。 
11. 


### 设计问题
1. 如果我们还需要扩展的话， 需要将这些服务拆分，通过RPC框架注册成RPC服务， 然后供客户端请求， 有时候一个请求需要多个服务交互完成，这时候就需要zookeeper 注册中心，做服务的管理和统计， 让各个服务能够及时的响应和并保持一致性。但是很简单的一个问题， 贪多就不能精。 在这个找实习的节骨眼上， 做分布式明显不是自己现阶段的主要矛盾。
2.  线程数量和cpu核数量请保持一致， 这样避免不同核时候， 线程调用上下文调用过慢。 
3. 这个项目并没有使用数据库连接池， 因此每次查询都要创建数据库连接类效率比较低效。 
4.  用户和群的关系是多对多， 因此必须有一个中间表反应多对多之间的关系， 这里我们使用了一个id和组id联合主键的表作为中间表， 反应了用户和表的关系。 这是表的设计问题。
5.  创建群等操作没有ack， 我们可以自己添加。 
6. 不用担心json输入错误，我们调试时候是自己手动输入json， 而实际发送信息的是客户端， 到时候发送的格式是固定的。 
7.  可以自学一些界面库或者前端的内容，将客户端从termail改成界面类型。 这是加分项。 
8. 注意这里我们没有使用redis的key-value这些内容，而是用了redis的一个发布订阅的小功能。因此如果面试时候被问到， 很可能关注点都不一样。 人家关注的数据如何保持一致性， 存储的原理。 我用的只有发布订阅设计模式。 
9. 数据库可以使用基于java语言开发的mycat中间件 ， 做分表分库， 主从复制，读写分离。 
10. 有的表不需要创建额外的数据结构去定义数据， 有的复杂的需要。 各种表的查找问题：  查找好友的话， 需要求用户表和好友表的交集。  查找离线信息的话是单表查询。 查找用户的话也是单表查询。 创建组的话就在allgroup里面添加， 加入组的话就是添加到组成员表， 查询用户所在组是多对多的关系， 查找成员表中特定id的组， 这些组联合allgroup 查出来结果，  查询群组的用户信息。 
11.  主要操作stl的容器， 对其增删改查都是线程不安全的 。要加锁。 




# 微服务聊天服务器
## 基础知识
### 1. probuff
 1. probuf可以看成是一个新的协议， 可以压缩的一个协议。 定义好协议proto之后会生成pb. cc.pb.h 这两个文件。 需要交互的时候， 我们给对方proto ， 对方生成自己语言版本的 代码和头文件之后就可以解析出来。 但是这样有一个麻烦就是每次数据协议更改， 都要重新生成。但是快呀。每个语言的编译代码和头文件都有序列化和反序列化这些代码。只不过定义的方式不一样。 proto采用vlant压缩的。 
2.  
### 2. zookeeper 
1. zookeeper的功能很多，常用的就是一个服务注册和发现， 但是像一些watch等api可以实现发布订阅功能，此外zk还支持分布式锁等，负载均衡。 我们这个项目中就是只使用了一个服务注册和发现的功能。

### 3. redis
1.  redis作为一个消息中间件有很多功能， 这里我们只用了一个，  Redis 服务器主要存储了用户的Host信息如下： id号 ip：host 例：10086 "127.0.0.1:3001"  先去 Redis 服务器上查询这个用户是否在线；如果在线，取得它的 Host 信息.。  之前项目的发布订阅功能取消了，直接用这个代替， 拿到对应的服务所在地址，发送一个消息， 接收方拿到这个消息之后找本地的链接conn, 进行通信。 

### 4. nginx 
3. 负载均衡和反向代理功能就不说了
### 5.  rpc 
rpc框架的实现逻辑： 
服务方：
1. rpc服务器类就是首先传入rpc服务类进去， 然后调用run成员函数。
整个 run 其实就是干了这么几件事情：
因为底层调用的是muduo网络库，所以这里会获取ip地址和端口号，然后初始化网络层
然后去设置一个连接回调以及发生读写事件时候的回调函数（后面说）
然后创建zookeeper配置中心，将这些方法的信息以及本机的IP地址注册到zookeeper
然后开启本机服务器的事件循环，等待其他服务器的连接
2. rpc服务类是基于UserServiceRpc.pb.cc.h 重写的， 重写里面的登录函数绑定成本地的函数了， 并建立了函数对象的map表。 那么还有一个问题就是发送过来如何找到的是这个类下的函数呢？这个好像就是直接去zookeeper里面去查的。但是还要找到具体的函数呀， 哦 原来是这个服务类继承的就是rpcprobuf类，进行成员函数的重写的。发过来通过基类指针可以指向具体的服务。 
3. 这里说一下muduo读写回调中干了啥， 首先是给一个probuf ::done指针， 这个指针绑定了发送序列化数据的函数，但是不执行。 这样当每次执行类似login服务的时候， 都会运行这个done指向的函数，让这个函数去发送序列化数据。

客户端：
客户端调用stub， stub里面传入一个指针， 这个指针在login方法中去调用callmethod函数， 这个callmethod函数至关重要， 主要实现了
组织要发送的 request_str 字符串
从zookeeper中拿到服务端的 ip 和 port，连接服务端
发送 request_str
接受服务端返回过来的 response 字符串并反序列化出结果


 ## 整体架构
1. set 模型： 整个ByteTalk整体设计抽象为由多台服务器组合而成的一台超级性能的服务器，这些服务器形成一个小集合，部署一整套对外的服务。set模型弥补了单机能力的不足，对业务组合搭配成一个单元。本质上是对服务的一个高内聚的封装。
![dd](https://img-blog.csdnimg.cn/img_convert/ad030f4f2083889a981f215738ce57ac.png)2.  分布式项目整体的框架如下。 首先的也是采用nginx去转发用户请求， 转发到多个超级集群中，每个超级集群是一整套业务。这个集群中有一个网关服务器转发到各个服务，实际上就是集群服务中的具体业务功能不在本地实现，使用rpc去调用这个逻辑。 因此我们现在来看这个框架就明显了。

2.  ProxyService 作为整个服务单元的入口（底层就是一个网络类加一个service类。 网络类转发数据到单例的service类的handle函数中得到函数对象， 拿到这个函数对象后将数据转发过去），整个服务单元对外暴露的也是它的 Host 信息，他从文件配置中拿到ip后将本地服务配置成网关服务器， 也就是nginx的下一层。  在封装了muduo库的server类中，对于客户端的请求信息，它会首先通过单例业务类中函数对象map表找到函数对象， 然后调用。 也就是实现了判断这个信息是哪个业务（难免要把所有probuf全部引用过来），如果是服务器的业务，它就会去Zookeeper注册中心，找到提供这个服务的服务节点，并把这个请求序列后发送过去。 
- +  登录业务的话去发送到业务服务器上， 如果响应登录成功的话，在redis上注册这个用户所在的服务器单元， 并在本地的链接map上添加id和本地和nginx链接的conn。
- + 对于群消息而言， 我们拿到后判断能否在本地的已经链接的数据中找到这个对应的conn，找到之后使用conn发送。 
- + 注册注销，添加好友 ， 获取用户信息，好友列表， 离线信息， 加群， 创建群， 群成员信息这些服务就没有任何额外的处理， 都是转发的。

3.  每个具体的业务服务也都会有一个抽象节点，以登录、注册节点：UserService为例 。 抽象节点收到一个消息，就会去zookeeper注册中心中获取一个可用的服务节点UserServer x，然后将这个消息派发给它，让它去执行。UserServer x会和持久层的 mysql 进行交互，具体的读取这个用户信息。（这里面没有实现对象的orm封装）。
- +  我们来继续看一下里面的逻辑，  从userservice开始， 这个就相当于一个调用者， 它里面对stub这个桩进行重写， 里面的实现步骤就是重写登录退出注册函数， 这些函数的步骤就是先调用zk客户端去获取当前服务的站点信息， 然后选择一个发送给真正的服务处理端。注册和退出是同理的。  继续走到userserver服务中，  这个是服务的真实落脚点。  这个就是服务的提供者， UserServer 大体上还是分为两层：网络层和业务层。网络层还是基于muduo网络库构建， 在run函数里启动网络层绑定回调（注意之前看很多代码都是叉开了，这里没有拆开让我刚开始看的时候比较迷。 ）run业务层则是首要的就是向zookeeper中去注册这个节点。一般是在/UserService目录下，以便抽象节点能够去发现服务。注意这个是临时节点，断开就没了。 然后还有回调的业务层，在这里面我们解析数据， 将解析出来的数据放到对应的本地方法中， 本地方法通过数据库线程连接池拿到一个ptr， 去查询，结果进行返回。  这里面的业务比较简单都是单表查询。 
- + 其他业务类似。
- + 聊天服务器是没有抽象节点了， 直接本身就是在做处理， 因为这个连天服务器可能会创建多个， 一个个人聊天消息， ChatServer 会先去 Redis 服务器上查询这个用户是否在线；如果在线，取得它的 Host 信息（也就是用户所在的服务单元），然后去已建立的连接map 中看是否建立过，如果没有建立，那么就建立，然后将这个连接放入map。接下来将这条信息转发过去；如果不在线，就将这个消息存储到 mysql 的OfflineMsg表中，供客户端下次上线时读取。
- + 群聊天没有实现，这里感觉不解耦，放到聊天里面， 我们多表查询到用户之后，依次去发，这样做一下估计可以的。

## 不足之处
1. 数据表的操作和意义不熟练， 还需要再复习
2. redis的发布订阅任务底层不熟练
3. 风不是群聊天没有实现，我们多表查询到用户之后，依次去发，这样做一下估计可以的。



#   参考文献
4. https://blog.csdn.net/QIANGWEIYUAN/article/details/89023980
5. 服务器编程教程
6. https://blog.csdn.net/lihao19910921/article/details/81907795
7. https://blog.csdn.net/tjcyjd/article/details/69683360

#   版本记录
1. 完成初步版本。  2021.4
2. 重新复习和完善文档，整理出来问题。  2021.7.10
3. 完善分布式相关的技术介绍  2021.8.2





